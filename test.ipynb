{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "X_ujyBab-g62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from imutils import paths"
      ],
      "metadata": {
        "id": "NPaDyFFR-_So"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 256\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 8"
      ],
      "metadata": {
        "id": "S51glPNQ_FFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For keypoints\n",
        "def unnormalize_and_scale_labels(keypoints, max_val):\n",
        "    keypoints = tf.math.scalar_mul(max_val, tf.math.add(keypoints, 0.5))\n",
        "    return keypoints"
      ],
      "metadata": {
        "id": "bivu1agf_LP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_tfrecord(example):\n",
        "    # feature map for extraction of data from TFRecord\n",
        "    features = {\n",
        "        'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image_mask': tf.io.FixedLenFeature([], tf.string),\n",
        "        'label': tf.io.FixedLenFeature([42], tf.float32),\n",
        "    }\n",
        "    image_features = tf.io.parse_single_example(example, features)\n",
        "\n",
        "    # For images\n",
        "    image = tf.io.decode_raw(image_features['image_raw'], out_type = tf.uint8)\n",
        "    image = tf.reshape(image, [256, 256, 3])\n",
        "\n",
        "    # For keypoints\n",
        "    labels = tf.reshape(image_features['label'], [21, 2])\n",
        "    labels = unnormalize_and_scale_labels(labels, IMG_SIZE)\n",
        "    labels = tf.dtypes.cast(labels, tf.float32)\n",
        "    return image, labels\n"
      ],
      "metadata": {
        "id": "kqCdgIWI_Ruj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(filenames):\n",
        "    \"\"\"\n",
        "    Load each TFRecord\n",
        "    \"\"\"\n",
        "    ignore_order = tf.data.Options()\n",
        "    ignore_order.deterministic = False\n",
        "\n",
        "    files = tf.data.Dataset.list_files(filenames)\n",
        "    dataset = files.with_options(ignore_order)\n",
        "    dataset = dataset.interleave(tf.data.TFRecordDataset, cycle_length=512, num_parallel_calls=AUTO)\n",
        "    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "dFCWIPk9_W06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tran_dir = \"/content/drive/MyDrive/archive/train\"\n",
        "train_tfrecord_names = list(paths.list_files(\"/content/drive/MyDrive/archive/train\"))"
      ],
      "metadata": {
        "id": "H863hILP_jZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(filenames)"
      ],
      "metadata": {
        "id": "HMaSwVsL7aU8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}